\documentclass[11pt,a4paper,twoside]{report}

\usepackage[ngerman,USenglish]{babel} % Swap languages with \selectlanguage{...}
\usepackage[utf8]{inputenc} % to write characters (à,Ü,...) in the source
\usepackage[T1]{fontenc} % make characters (à,Ü,...) appear as such in the pdf
\usepackage{lmodern}
\usepackage{amsmath,amssymb,amsfonts} % math stuff
\usepackage{array} % better implementation of tabular and array environments
\usepackage{graphicx} % graphics inclusion
\usepackage{fancyhdr} % beautiful page headers/footers
\usepackage{emptypage} % removes header/footer from empty pages
\usepackage{microtype} % beautiful typesetting
\usepackage{verbatim} % typesetting raw text

% More packages.  Uncomment what you need:

% \usepackage{bbm} % if you need $\mathbbm{1}$
% \usepackage{mathrsfs} % if you need more math script fonts $\mathscr{A}$
% \usepackage{pifont} % more symbols, e.g., circled numbers

\usepackage{pict2e} % a better picture environment
\usepackage{tikz} % versatile drawing facilities
\usetikzlibrary{fit} % used for the example tikzpicture
\usepackage{pgfplots} % versatile plotting facilities

% \usepackage{psfrag}
% \usepackage[crop=pdfcrop,cleanup={.tex,.dvi,.ps,.pdf,.log,.aux,.idx,.toc,.out}]
% {pstool} % a pdf-compatible alternative to psfrag.

% \usepackage{amsthm} % or % \usepackage{theorem} % for theorems

% \usepackage{algorithmicx} % typesetting algorithms

% \usepackage[labelfont={md}]{subfig} % for sub-floats, e.g. sub-figures

\usepackage{url} % write URLs
\usepackage{factorGraphs} % package that has macros for factor graphs

% the last package to load:
\usepackage[bookmarksnumbered=true,hypertexnames=false]{hyperref} % hyperlinks

% Page layout
\setlength{\oddsidemargin}{2.5cm}
\setlength{\evensidemargin}{0.5cm}
\addtolength{\textheight}{0.0cm}
\addtolength{\textwidth}{0.0cm}
\addtolength{\topmargin}{0.0cm}
\setlength{\headheight}{3ex}

\renewcommand{\baselinestretch}{1.2}

%\newcommand{\vecbf}{\overrightarrow{\mathbf{\vec}}_{X_{k}}}
%\newcommand{\messF}[1]{\vec{#1}_{X_{k}}}
%\newcommand{\messF}[3]{\vec{#1}_{{#2}_{k{#3}}}}
\newcommand{\messF}[3]{\overrightarrow{#1}_{{#2}_{k{#3}}}}
\newcommand{\messB}[3]{\overleftarrow{#1}_{{#2}_{k{#3}}}}

\newcommand{\mat}[1]{\mathbf{#1}}
%\overrightarrow{\mathbf{m}}_{X_{k}}

% Here the document starts
\begin{document}
\pagestyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------       Update Rules     ---------------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Derivation of Update Rules for Kalman-Based PLL}
In Figure \ref{factor_graph} we can see a factor graph representation of a Kalman-based phase-locked loop. The matrices $A$, $C$ and the observed measurements $y_k$ are given as follows

\begin{align*}
	&\mat{A} = R(\omega_0) = 
		\begin{bmatrix}
			\cos{(\omega_0)} & -\sin{(\omega_0} \\
			\sin{(\omega_0} & \cos{(\omega_0}
		\end{bmatrix},
	\\
	&\mat{C} = 
		\begin{bmatrix}
			1 & 0
		\end{bmatrix},
	\\
	&Y_k = \cos({\omega_0k + \phi}) + Z_k, \qquad Z_k \overset{i.i.d}{\sim} \mathcal{N}\left(0, \sigma^2\right).
\end{align*}

Since $Z_k$ is a Gaussian random variable it follows that all random variables in the factor graph are Gaussian. The states $X_k$ can therefore be described by its mean vector and covariance matrix.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}
		\pllFactorGraph{0}{0}{1}{1}{k-1}{k}
	\end{tikzpicture}

  	\caption[Exemplary factor graph]
   	{Factor graph representation of a Kalman filter's \textit{k}th cell.}
	\label{factor_graph}
\end{figure}

In every step $k$, a new sample $y_k$ is observed. Together with this sample and the previous state $X_{k-1}$, using Gaussian message passing, we can calculate the next state estimate $X_k$.

We begin the message passing algorithm by computing the message given by the observed samples $y_k$ \cite{SIP}

\begin{align}
	\label{eq: noise}
	\messF{m}{Z}{} = 0  \qquad &\messF{V}{Z}{} = \sigma^2 \\
	\label{eq: sample}
	\messB{m}{Y}{} = y_k  \qquad &\messB{V}{Y}{} = 0.
\end{align}

In a next step, we add the noise in Eq. (\ref{eq: noise}) to the observed sample in Eq. (\ref{eq: sample}) to get the message at $Y_k$
\begin{align}
	\label{eq: noisy samples}
	\messB{m}{Y}{} = y_k \qquad &\messB{V}{Y}{} =  \sigma^2.
\end{align}

With these results, we can now compute the messages at the equality constraint
\begin{align}
	\label{eq: previous state}
	\messF{m}{X''}{} = \mat{A}\messF{m}{X}{-1} \qquad &\messF{V}{X''}{} = \mat{A}\messF{V}{X}{-1}\mat{A}_T \\
	\label{eq: input}
	\messB{W}{X'}{} = \mat{C}^T\messB{W}{Y}{}\mat{C}  \qquad &\messB{W}{X'}{}\messB{m}{X'}{} = \mat{C}^T\messB{W}{Y}{}\messB{m}{Y}{},
\end{align}

where $\messB{W}{X'}{}$ denotes the precision matrix with the following equality

\begin{equation*}
	\messF{W}{X}{}^{-1} = \messF{V}{X}{},
\end{equation*}

and $\messB{W}{X'}{}\messB{m}{X'}{}$ denotes the weighted mean. The set of equations in (\ref{eq: input}) can be simplified by using the set of equations in (\ref{eq: noisy samples})

\begin{equation*}
	\messB{W}{X'}{} = \mat{C}^T\frac{1}{\sigma^2}\mat{C}  \qquad \messB{W}{X'}{}\messB{m}{X'}{} = \mat{C}^T\frac{1}{\sigma^2}y_k.
\end{equation*}


Hence we can characterize $X_k$ by its precision matrix and its weighted mean (update rules). Note that $\mat{A}$ is an invertible matrix since 

\begin{align}
  \label{eq: precision matrix}
  \messF{W}{X}{} &= \messF{W}{X''}{} + \messB{W}{X'}{} \\
  &= \left(\mat{A}\messF{V}{X}{-1}\mat{A}^T\right)^{-1} + \mat{C}^T\frac{1}{\sigma^2}\mat{C} \\
  & = \left(\mat{A}\messF{V}{X}{-1}\mat{A}^T\right)^{-1} + \frac{1}{\sigma^2}\mat{C}^T\mat{C} \\
  & = \mat{A}^{-T}\messF{W}{X}{-1}\mat{A}^{-1} + \frac{\mat{C}^T\mat{C}}{\sigma^2}  \\
  & = \mat{A}\messF{W}{X}{-1}\mat{A}^{-1} + \frac{\mat{C}^T\mat{C}}{\sigma^2},
\end{align}

\begin{align}
  \label{eq: weighted mean}
  \messF{W}{X}{}\messF{m}{X}{} &= \messF{W}{X''}{}\messF{m}{X''}{} + \messF{W}{X'}{}\messF{m}{X'}{} = \\
  &= \left(\mat{A}\messF{V}{X}{-1}\mat{A}^T\right)^{-1}\mat{A}\messF{m}{X}{-1} + \mat{C}^T\frac{1}{\sigma^2}y_k \\
  &= \left(\messF{V}{X}{-1}\mat{A}^T\right)^{-1}\underbrace{\mat{A}^{-1}\mat{A}}_{\mat{I}}\messF{m}{X}{-1} + \mat{C}^T\frac{1}{\sigma^2}y_k \\
  &= \mat{A}^{-T}\messF{W}{X}{-1}\messF{m}{X}{-1} + \frac{\mat{C}^T}{\sigma^2}y_k \\
  &= \mat{A}\messF{W}{X}{-1}\messF{m}{X}{-1} + \frac{\mat{C}^T}{\sigma^2}y_k,
\end{align}

where the last step in the particular update equations follows from the fact that $\mat{A}$ is the rotation matrix and therefore an orthogonal matrix, i.e., its transpose is equal to its inverse

\begin{equation*}
	\mat{A}^T = \mat{A}^{-1}.
\end{equation*}

In a next step we try to get to an expression for the covariance matrix and the mean vector by using the Matrix Inversion Lemma (\ref{eq: matrix inversion lemma})
 
\begin{align}
	\label{eq: matrix inversion lemma}
	\left(\mat{B} + \mat{DEF}\right)^{-1} = \mat{B}^{-1} - \mat{B}^{-1}\mat{D}\left(\mat{E}^{-1} + \mat{F}\mat{B}^{-1}\mat{D}\right)^{-1}\mat{F}\mat{B}^{-1}.
\end{align}

\noindent Thus we get the following assignments from equation (\ref{eq: precision matrix})

\begin{align}
	\label{eq: assignments MIL}
	& \mat{B} = \mat{A}^{-T}\messF{W}{X}{-1}\mat{A}^{-1}, \\
	& \mat{D} = \mat{C}^T, \\
	& \mat{E} = \frac{1}{\sigma^2}, \\
	& \mat{F} = \mat{C}.
\end{align}

Using these, the inverse of equation (\ref{eq: precision matrix}), i.e., the covariance matrix can be written as

\begin{align}
	\label{eq: update rule, covariance}
	\messF{V}{X}{} &= \left[\mat{A}^{-T}\messF{W}{X}{-1}\mat{A}^{-1} + \frac{\mat{C}^T\mat{C}}{\sigma^2}\right]^{-1} \\
	\nonumber
	&= \left(\mat{A}^{-T}\messF{W}{X}{-1}\mat{A}^{-1}\right)^{-1} \\
	& - \left(\mat{A}^{-T}\messF{W}{X}{-1}\mat{A}^{-1}\right)^{-1}\mat{C}^T\left(\sigma^2 + \mat{C}\left(\mat{A}^{-T}\messF{W}{X}{-1}\mat{A}^{-1}\right)^{-1}\mat{C}^T\right)^{-1}\mat{C}\left(\mat{A}^{-T}\messF{W}{X}{-1}\mat{A}^{-1}\right)^{-1} \\
	\nonumber
	&= \mat{A}\messF{V}{X}{-1}\mat{A}^T - \mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T\underbrace{\left(\sigma^2 + \mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T\right)^{-1}}_{=:G}\mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T \\
	&= \mat{A}\messF{V}{X}{-1}\mat{A}^T - \mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^TG\mat{CA}\messF{V}{X}{-1}\mat{A}^T
\end{align}

\noindent where

\begin{equation*}
	G := \left( \sigma^2 + \mat{C} \mat{A}\messF{V}{X}{-1} \mat{A}^T\mat{C}^T \right)^{-1}.
\end{equation*}

The mean vector $\messF{m}{X}{}$ can be retrieved by multiplying the matrix $\messF{V}{X}{}$ with (\ref{eq: weighted mean})

\begin{align}
	\label{eq: update rule, mean vector}
	\messF{m}{X}{} &= \messF{V}{X}{} \left( \messF{W}{X}{}\messF{m}{X}{} \right) \\
	&= \left(\mat{A}\messF{V}{X}{-1}\mat{A}^T - \mat{A}\messF{V}{X}{-1}\mat{A}^T \mat{C}^T G\mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\right) \\
	&\nonumber \quad \cdot \left( \mat{A}^{-T}\messF{W}{X}{-1}\messF{m}{X}{-1} + \frac{\mat{C}^T}{\sigma^2}y_k \right) \\
	&= \mat{A} \underbrace{\messF{V}{X}{-1}\mat{A}^T\mat{A}^{-T}\messF{W}{X}{-1}}_{\mat{I}} \messF{m}{X}{-1} - \mat{A}\messF{V}{X}{-1}\mat{A}^T \mat{C}^T G\mat{C}\mat{A}\underbrace{\messF{V}{X}{-1}\mat{A}^T\mat{A}^{-T}\messF{W}{X}{-1}}_{\mat{I}}\messF{m}{X}{-1} \\
	&\nonumber \quad + \left(\mat{A}\messF{V}{X}{-1}\mat{A}^T - \mat{A}\messF{V}{X}{-1}\mat{A}^T \mat{C}^T G\mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\right) \cdot \left( \frac{\mat{C}^T}{\sigma^2}y_k \right) \\
	&= \mat{A} \messF{m}{X}{-1} - \mat{A}\messF{V}{X}{-1}\mat{A}^T \mat{C}^T G\mat{C}\mat{A}\messF{m}{X}{-1} \\
	&\nonumber \quad + \left(\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T - \mat{A}\messF{V}{X}{-1}\mat{A}^T \mat{C}^T G\mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T\right) \cdot \left(\frac{1}{\sigma^2}\right) \cdot y_k \\
	&= \mat{A} \messF{m}{X}{-1} - \left(\mat{A}\messF{V}{X}{-1}\mat{A}^T \mat{C}^T G\right)\mat{C}\mat{A}\messF{m}{X}{-1} \\
	&\nonumber \quad + \left(\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T\right) \underbrace{\left(\mat{I} - G\mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T\right) \cdot \left(\frac{1}{\sigma^2}\right)}_{=:\lambda} \cdot y_k.
\end{align}

The factor $\lambda$ can further be simplified to

\begin{align}
	\label{eq: lambda factor}
	\lambda &:= \left(\mat{I} - G\mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T\right) \cdot \left(\frac{1}{\sigma^2}\right) \\
	&= \left(GG^{-1} - G\mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T\right) \cdot \left(\frac{1}{\sigma^2}\right) \\
	&= G\left(G^{-1} - \mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T\right) \cdot \left(\frac{1}{\sigma^2}\right) \\
	&= G\left(\sigma^2 + \underbrace{\mat{C} \mat{A}\messF{V}{X}{-1} \mat{A}^T\mat{C}^T - \mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T}_{=0}\right) \cdot \left(\frac{1}{\sigma^2}\right) \\
	&= G\left(\sigma^2 \right) \cdot \left(\frac{1}{\sigma^2}\right) \\
	&= G,
\end{align}

where we used the fact, that $G^{-1} = \sigma^2 + \mat{C} \mat{A}\messF{V}{X}{-1} \mat{A}^T\mat{C}^T$. So we finally find the following condensed expression for $\messF{m}{X}{}$

\begin{align}
	\label{eq: update rule, mean vector}
	\messF{m}{X}{} &= \mat{A} \messF{m}{X}{-1} - \left(\mat{A}\messF{V}{X}{-1}\mat{A}^T \mat{C}^T G\right)\mat{C}\mat{A}\messF{m}{X}{-1} + \left(\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T G\right) y_k \\
	&= \mat{A} \messF{m}{X}{-1} + \mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T G \left( y_k - \mat{C}\mat{A}\messF{m}{X}{-1} \right).
\end{align}

%and where the last step (see equation (\ref{eq: update rule, orthogonal matrix})) follows from the fact that $\mat{A}$ is the rotation matrix and therefore an orthogonal matrix, i.e., its transpose is equal to its inverse
%
%\begin{equation*}
%	\mat{A}^T = \mat{A}^{-1}.
%\end{equation*}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------       Amplitude and Phase Estimate     -----------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Amplitude and Phase Estimate and Cost Function}
The predicted signal estimate given the measurements ${y_1,...,y_{k-1}}$ can be written as

\begin{equation*}
	\tilde{y}_k = \mat{CA}\messF{m}{X}{-1},
\end{equation*}

and the corrected estimate given the measurements ${y_1,...,y_k}$ as

\begin{equation*}
	\hat{y}_k = \mat{C}\messF{m}{X}{-1}.
\end{equation*}

The difference between the corrected and the predicted estimate can be deduced as

\begin{align}
	\hat{y}_k - \tilde{y}_k &= \mat{C}\left(\messF{m}{X}{} - \mat{A}\messF{m}{X}{-1}\right) \\
	\nonumber
	&= \mat{C}\left(\messF{m}{X}{} - \messF{m}{X}{} + \underbrace{\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^TG}_{=:\mat{B}_k}\left(y_k-\mat{CA}\messF{m}{X}{-1}\right)\right) \\
	\label{eq: corrected-predicted estimate}
	&= \mat{C}\mat{B}_k\left(y_k - \tilde{y}_k\right)
\end{align}

Since both the input signal and estimate is known to be sinusoidal the mean vector at time index k can be written as \cite{ST:Malmberg}

\begin{equation*}
	\messF{m}{X}{} = \hat{a}_k
		\begin{bmatrix}
			\cos{\left(\omega_0k + \hat{\phi}_k\right)} \\
			\sin{\left(\omega_0k + \hat{\phi}_k\right)}
		\end{bmatrix}
\end{equation*}

and subsequently

\begin{align}
	& y_k = a\cos{\left(\omega_0k + \phi\right)} + Z_k, \qquad Z_k \overset{i.i.d}{\sim} \mathcal{N}\left(0, \sigma^2\right), \\
	& \tilde{y}_k = \hat{a}_{k-1}\cos{\left(\omega_0k + \hat{\phi}_{k-1}\right)}, \\
	& \hat{y}_k = \hat{a}_k\cos{\left(\omega_0k + \hat{\phi}_k\right)}
\end{align}


Now we consider the scenario where only the phase is tracked and the amplitude is assumed to be $\hat{a}_k = \hat{a}_{k-1} = a_k$. If the phase estimation error is small such that $\left|\hat{\phi}_k - \phi\right|\ll1$ and $\left|\hat{\phi}_{k-1} - \phi\right|\ll1$, equation (\ref{eq: corrected-predicted estimate}) can be reduced to

\begin{align}
	a\left(\cos{\left(\omega_0k + \hat{\phi}_k\right)}- \cos{\left(\omega_0k + \hat{\phi}_{k-1}\right)}\right) &= 
	a\alpha_k\left(\cos{\left(\omega_0k + \hat{\phi}_k\right)}- \cos{\left(\omega_0k + \hat{\phi}_{k-1}\right)}\right) \\
	\sin{\left(\frac{\hat{\phi}_k - \hat{\phi}_{k-1}}{2}\right)} &\approx \alpha_k\sin{\left(\frac{\phi - \hat{\phi}_{k-1}}{2}\right)} \\
	\label{eq: phase diff}
	\hat{\phi}_k - \hat{\phi}_{k-1} &\approx \alpha_k\phi - \hat{\phi}_{k-1}.
\end{align}

Thus follows from equation (\ref{eq: phase diff}) that the phase update can be approximated as

\begin{equation}
	\hat{\phi}_k \approx \alpha_k\phi + \left(1-\alpha_k\right)\hat{\phi}_{k-1}.
\end{equation}

In a similar way, the amplitudes can be extracted under the condition that $\hat{\phi}_k = \hat{\phi}_{k-1} = \phi$

\begin{align}
	\hat{a}_k\cos{\left(\omega_0k + \phi\right)} - \hat{a}_{k-1}\cos{\left(\omega_ok + \phi\right)} &= \alpha_k\left(a\cos{\left(\omega_0k + \phi\right)} - \hat{a}_{k-1}\cos{\left(\omega_ok + \phi\right)}\right) \\
	\hat{a}_k - \hat{a}_{k-1} &= \alpha_k\left(a-\hat{a}_{k-1}\right) \\
	\hat{a}_k &= \alpha_ka + \left(1-\alpha_k\right)\hat{a}_{k-1}.
\end{align}

The cost function for the PLL then can be written as follows

\begin{equation}
	J = \mathbb{E}\left[\right]
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------       Independence of state update from noise     ------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Independence of State Update from Noise}
By induction and for a time index $k>0$, the precision matrix update rule in eq. (\ref{eq: precision matrix}) can be written as follows

\begin{equation}
	\label{eq: update rule}
	\messF{W}{X}{} = \sum_{j=0}^{k-1}\left(\mat{A}^{-T}\right)^j\frac{\mat{C}^T\mat{C}}{\sigma^2}\left(\mat{A}^{-1}\right)^{j}.
\end{equation}

Since $\mat{A}$ is a rotation matrix it can be diagonalized in an orthonormal basis in $\mathcal{C}$ such that

\begin{equation}
	\mat{A} = \mat{Q\Lambda}\mat{Q}^H,
\end{equation}

where $\mat{Q}$ is a unitary matrix and $\mat{Q}^H$ denotes the its Hermitian transpose. The decomposition of the matrix $\mat{A}$ can be done as follows

\begin{align*}
	&\mat{Q} = \frac{1}{\sqrt{2}}
		\begin{bmatrix}
			1 & 1 \\
			-i & i
		\end{bmatrix},
	\\
	&\mat{\Lambda} = 
		\begin{bmatrix}
			\exp{(i\omega_0)} & 0 \\
			0 & \exp{(-i\omega_0)}
		\end{bmatrix}.
\end{align*}

In a next step, the new expression for $\mat{A}$ can be inserted into equation (\ref{eq: update rule}) \cite{ST:Malmberg}

\begin{align}
	\nonumber
	\messF{W}{X}{} &= \sum_{j=0}^{k-1}\left(\left(\left(\mat{Q\Lambda}\mat{Q}^H\right)^H\right)^{-j}\frac{\mat{C}^T\mat{C}}{\sigma^2}\left(\mat{Q\Lambda}\mat{Q}^H\right)^{-j}\right) \\
	\label{eq: update rule, unitary Q}
	&= \frac{1}{\sigma^2}\sum_{j=0}^{k-1}\left(\mat{Q}\left(\bar{\Lambda}\right)^{-j}\mat{Q}^H
		\begin{bmatrix}
			1 & 0 \\
			0 & 0
		\end{bmatrix}
		\mat{Q}\mat{\Lambda}^{-j}\mat{Q}^H\right)
	\\
	\nonumber
	&= \frac{1}{\sigma^2}\mat{Q}\sum_{j=0}^{k-1}\left(\mat{Q}\left(\bar{\Lambda}\right)^{-j}
		\begin{bmatrix}
			1 & 0 \\
			0 & 0
		\end{bmatrix}
		\mat{\Lambda}^{-j}\right)\mat{Q}^H
	\\
	\nonumber
	&= \frac{1}{\sigma^2}\mat{Q}\sum_{j=0}^{k-1}\left(
		\begin{bmatrix}
			\exp{(i\omega_0j)} & 0 \\
			0 & \exp{(-i\omega_0j)}
		\end{bmatrix}
		\begin{bmatrix}
			1 & 0 \\
			0 & 0
		\end{bmatrix}
		\begin{bmatrix}
			\exp{(-i\omega_0j)} & 0 \\
			0 & \exp{(i\omega_0j)}
		\end{bmatrix}
		\right)\mat{Q}^H
	\\
	\nonumber
	&= \frac{1}{\sigma^2}\mat{Q}\sum_{j=0}^{k-1}\left(
		\begin{bmatrix}
			\exp{(i\omega_0j)} & \exp{(i\omega_0j)} \\
			\exp{(-i\omega_0j)} & \exp{(-i\omega_0j)}
		\end{bmatrix}
		\begin{bmatrix}
			\exp{(-i\omega_0j)} & 0 \\
			0 & \exp{(i\omega_0j)}
		\end{bmatrix}
		\right)\mat{Q}^H
	\\
	\nonumber
	&= \frac{1}{\sigma^2}\mat{Q}\sum_{j=0}^{k-1}\left(
		\begin{bmatrix}
			\exp{(i\omega_0j)} & 0 \\
			0 & \exp{(-i\omega_0j)}
		\end{bmatrix}
		\begin{bmatrix}
			1 & 0 \\
			0 & 0
		\end{bmatrix}
		\begin{bmatrix}
			\exp{(-i\omega_0j)} & 0 \\
			0 & \exp{(i\omega_0j)}
		\end{bmatrix}
		\right)\mat{Q}^H
	\\
	\nonumber
	&= \frac{1}{\sigma^2}\mat{Q}\sum_{j=0}^{k-1}\left(
		\begin{bmatrix}
			1 & \exp{(2i\omega_0j)} \\
			\exp{(-2i\omega_0j)} & 1
		\end{bmatrix}
		\right)\mat{Q}^H
	\\
	\nonumber
	&= \frac{1}{\sigma^2}\mat{Q}\sum_{j=0}^{k-1}\left(
		\begin{bmatrix}
			1 & 0 \\
			0 & 1
		\end{bmatrix} +
		\begin{bmatrix}
			0 & \exp{(2i\omega_0j)} \\
			\exp{(-2i\omega_0j)} & 0
		\end{bmatrix}
		\right)\mat{Q}^H
	\\
	\label{eq: update rule, orthogonal basis}
	&= \frac{1}{\sigma^2}\left(\frac{k}{2}\mat{I}_2 + \mat{Q}\sum_{j=0}^{k-1}\left(
		\begin{bmatrix}
			0 & \exp{(2i\omega_0j)} \\
			\exp{(-2i\omega_0j)} & 0
		\end{bmatrix}
		\right)\mat{Q}^H\right)
\end{align}

where equation (\ref{eq: update rule, unitary Q}) follows from the unitary property of $\mat{Q}$. Then we rewrite the equation (\ref{eq: update rule, orthogonal basis}) as follows

\begin{align}
	\label{eq: update rule, geometric series}
	\sum_{j=0}^{k-1}\exp{\left(2i\omega_0j\right)} &= \frac{1-\exp{\left(2i\omega_0k\right)}}{1-\exp{\left(2i\omega_0\right)}} \\
	\nonumber
	&= \frac{\exp{\left(i\omega_0k\right)}\left(\exp{\left(i\omega_0k\right)}-\exp{\left(-i\omega_0k\right)}\right)}{\exp{\left(i\omega_0\right)}\left(\exp{\left(i\omega_0\right)}-\exp{\left(-i\omega_0\right)}\right)} \\
	\label{eq: update rule, euler}
	&= \exp{\left(i\omega_0\left(k-1\right)\right)}\frac{\sin{\left(\omega_0k\right)}}{\sin{\left(\omega_0\right)}}
\end{align}

where we used the geometric series in equation (\ref{eq: update rule, geometric series})

\begin{equation*}
	\sum_{n=0}^{n-1}ar^k = a\frac{1-r^n}{1-r},
\end{equation*}

and the following identity for the sine (derived from Euler's formula) (see equation (\ref{eq: update rule, euler}))

\begin{equation*}
	\sin{\left(x\right)} = \frac{1}{2i}\left(e^{ix} - e^-ix\right).
\end{equation*}

In a similar way we get the following equation

\begin{equation*}
	\sum_{j=0}^{k-1}\exp{\left(-2i\omega_0j\right)} = \exp{\left(-i\omega_0\left(k-1\right)\right)}\frac{\sin{\left(\omega_0k\right)}}{\sin{\left(\omega_0\right)}}.
\end{equation*}

Thus the second term in equation (\ref{eq: update rule, orthogonal basis}) can be written as

\begin{align}
	\nonumber
	& \mat{Q}\sum_{j=0}^{k-1}\left(
		\begin{bmatrix}
			0 & \exp{(2i\omega_0j)} \\
			\exp{(-2i\omega_0j)} & 0
		\end{bmatrix}
		\right)\mat{Q}^H
	\\
	\nonumber
	&= \frac{\sin{\left(\omega_0k\right)}}{2\sin{\left(\omega_0\right)}}
		\begin{bmatrix}
			1 & 1\\
			-i & i
		\end{bmatrix}
		\begin{bmatrix}
			0 & \exp{\left(i\omega_0\left(k-1\right)\right)} \\
			\exp{\left(-i\omega_0\left(k-1\right)\right)} & 0
		\end{bmatrix}
		\begin{bmatrix}
			1 & i \\
			1 & -i
		\end{bmatrix}
	\\
	\nonumber
	&= \frac{\sin{\left(\omega_0k\right)}}{2\sin{\left(\omega_0\right)}}
		\begin{bmatrix}
			\exp{\left(-i\omega_0\left(k-1\right)\right)} & \exp{\left(i\omega_0\left(k-1\right)\right)} \\
			i\exp{\left(-i\omega_0\left(k-1\right)\right)} & -i\exp{\left(i\omega_0\left(k-1\right)\right)}
		\end{bmatrix}
		\begin{bmatrix}
			1 & i \\
			1 & -i
		\end{bmatrix}
	\\
	\nonumber
	&= \frac{\sin{\left(\omega_0k\right)}}{2\sin{\left(\omega_0\right)}}
		\begin{bmatrix}
			2\cos{\left(\omega_0\left(k-1\right)\right)} & 2\sin{\left(\omega_0\left(k-1\right)\right)} \\
			2\sin{\left(\omega_0\left(k-1\right)\right)} & -2\cos{\left(\omega_0\left(k-1\right)\right)}
		\end{bmatrix}
	\\
	&= \frac{\sin{\left(\omega_0k\right)}}{\sin{\left(\omega_0\right)}}\mat{A}^{k-1}\mat{S}
\end{align}

where $\mat{S} = \begin{bmatrix} 1 & 0 \\
0 & -1 \end{bmatrix}$. Finally the precision matrix is now reduced to

\begin{equation*}
	\messF{W}{X}{} = \frac{1}{2\sigma^2}\left(k\mat{I}_2 + \frac{\sin{\left(\omega_0k\right)}}{\sin{\left(\omega_0\right)}}\mat{A}^{k-1}\mat{S}\right)
\end{equation*}

\begin{align}
	\messF{V}{X}{} &= \left(\messF{W}{X}{}\right)^{-1} \\
	&= \frac{2\sigma^2}{k^2-\left(\frac{\sin{\left(\omega_0k\right)}}{\sin{\left(\omega_0\right)}}\right)^2}\left(k\mat{I}_2 - \frac{\sin{\left(\omega_0k\right)}}{\sin{\left(\omega_0\right)}}\mat{A}^{k-1}\mat{S}\right)
\end{align}

\begin{align}
	\alpha_k &= \mat{CB}_k \\
	&= \mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^TG \\
	&= \mat{C}\mat{A}\messF{V}{X}{-1}\mat{A}^T\mat{C}^T\left( \sigma^2 + \mat{C} \mat{A}\messF{V}{X}{-1} \mat{A}^T\mat{C}^T \right)^{-1} \\
	&= \frac{2\left(k-\frac{\sin{\left(\omega_0k\right)}}{\sin{\left(\omega_0\right)}}\cos{\left(\omega_0\left(k+1\right)\right)}\right)}{k^2-\left(\frac{\sin{\left(\omega_0k\right)}}{\sin{\left(\omega_0\right)}}\right)^2 + 2\left(k-\frac{\sin{\left(\omega_0k\right)}}{\sin{\left(\omega_0\right)}}\cos{\left(\omega_0\left(k+1\right)\right)}\right)}
\end{align}

\clearpage

% Bibliography
\bibliographystyle{unsrt} % bibliography style in order of first citation
%\bibliographystyle{splncs}
\bibliography{references}

\end{document}
